import os
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import streamlit as st

# Define folder paths
folder_path_jobs = "Job"  
folder_path_personnel = "Person"  
desired_levels_path = "Ø´Ø§ÛŒØ³ØªÚ¯ÛŒ Ø±ÙØªØ§Ø±ÛŒ Ø±ÙˆØ³Ø§ÛŒ Ø§Ø¯Ø§Ø±Ø§Øª.xlsx"  
final_scores_path = "Ø´Ø§ÛŒØ³ØªÚ¯ÛŒ Ø±ÙØªØ§Ø±ÛŒ Ú©Ø§Ø±Ø´Ù†Ø§Ø³Ø§Ù†.xlsx"  

# Reading job files
all_jobs = []

# Iterate over job files in the specified folder
for file_name in os.listdir(folder_path_jobs):
    if file_name.endswith(".xlsx"):
        file_path = os.path.join(folder_path_jobs, file_name)
        df = pd.read_excel(file_path)
        # Check if necessary columns are present
        if "Ø³Ù…Øª" in df.columns and "Ø´Ø§Ø®Øµ" in df.columns:
            df = df[["Ø³Ù…Øª", "Ø´Ø§Ø®Øµ"]]  # Extract relevant columns
            all_jobs.append(df)

# Combine all job data into a single DataFrame
if all_jobs:
    jobs_df = pd.concat(all_jobs, ignore_index=True)
else:
    st.error("Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ø´ØºÙ„ÛŒ Ù…Ø¹ØªØ¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    st.stop()

# Reading desired levels
desired_levels_df = pd.read_excel(desired_levels_path)

# Ensure necessary columns exist
if "Ø³Ù…Øª" not in desired_levels_df.columns or "Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨" not in desired_levels_df.columns:
    st.error("ÙØ§ÛŒÙ„ Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³Øª.")
    st.stop()

# Group by job titles and calculate the mean of desired levels
desired_levels_grouped = desired_levels_df.groupby("Ø³Ù…Øª")["Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨"].mean().reset_index()

# Reading personnel files
all_personnel_scores = []

# Iterate over personnel files in the specified folder
for file_name in os.listdir(folder_path_personnel):
    if file_name.endswith(".xlsx"):
        file_path = os.path.join(folder_path_personnel, file_name)
        df = pd.read_excel(file_path)
        # Check if necessary columns are present
        if "Ú©Ø¯ Ù¾Ø±Ø³Ù†Ù„ÛŒ" in df.columns and "Ø´Ø§Ø®Øµ" in df.columns:
            df = df[["Ú©Ø¯ Ù¾Ø±Ø³Ù†Ù„ÛŒ", "Ø´Ø§Ø®Øµ"]]
            all_personnel_scores.append(df)

# Combine all personnel data into a single DataFrame
if all_personnel_scores:
    personnel_scores_df = pd.concat(all_personnel_scores, ignore_index=True)
else:
    st.error("Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ù¾Ø±Ø³Ù†Ù„ÛŒ Ù…Ø¹ØªØ¨Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
    st.stop()

# Reading final scores
final_scores_df = pd.read_excel(final_scores_path)

# Ensure necessary columns exist
if "Ú©Ø¯ Ù¾Ø±Ø³Ù†Ù„ÛŒ" not in final_scores_df.columns or "Ù†Ù…Ø±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ" not in final_scores_df.columns:
    st.error("ÙØ§ÛŒÙ„ Ù†Ù…Ø±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³Øª.")
    st.stop()

# Group by personnel ID and calculate the mean of final scores
final_scores_df = final_scores_df.groupby("Ú©Ø¯ Ù¾Ø±Ø³Ù†Ù„ÛŒ")["Ù†Ù…Ø±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ"].mean().reset_index()

# Main UI layout
st.markdown(
    """
    <style>
    body {
        direction: rtl;
        text-align: right;
    }
    .stButton button {
        font-family: "B Nazanin";
        font-size: 18px;
    }
    .stTextInput label {
        font-family: "B Nazanin";
        font-size: 18px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# User input for job selection
st.markdown("#### Ù†Ø§Ù… Ø´ØºÙ„ Ù…ÙˆØ±Ø¯Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:")
selected_job = st.text_input("Ù†Ø§Ù… Ø´ØºÙ„:")

if selected_job:  
    # Check if the selected job exists in the job dataset
    if selected_job in jobs_df["Ø³Ù…Øª"].values:
        # Fetch the mean desired level for the selected job
        if selected_job in desired_levels_grouped["Ø³Ù…Øª"].values:
            mean_desired_level = desired_levels_grouped[desired_levels_grouped["Ø³Ù…Øª"] == selected_job]["Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨"].values[0]
            st.info(f"ğŸ“Š Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨ Ø¨Ø±Ø§ÛŒ Ø³Ù…Øª '{selected_job}': {mean_desired_level:.2f}")
        else:
            st.warning("Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø³Ù…Øª Ø³Ø·Ø­ Ù…Ø·Ù„ÙˆØ¨ÛŒ ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")

        # Fetch the criteria for the selected job
        selected_job_criteria = jobs_df[jobs_df["Ø³Ù…Øª"] == selected_job]["Ø´Ø§Ø®Øµ"].values
        if len(selected_job_criteria) > 0:
            vectorizer = TfidfVectorizer()
            job_vector = vectorizer.fit_transform(selected_job_criteria)

            # Calculate TF-IDF for personnel data
            personnel_vectors = vectorizer.transform(personnel_scores_df["Ø´Ø§Ø®Øµ"].astype(str))
            similarity_scores = cosine_similarity(job_vector, personnel_vectors)[0]

            # Add similarity scores to personnel data
            personnel_scores_df["Ø§Ù…ØªÛŒØ§Ø² Ø´Ø¨Ø§Ù‡Øª"] = similarity_scores

            # Merge with final scores to include final score
            merged_df = personnel_scores_df.merge(final_scores_df, on="Ú©Ø¯ Ù¾Ø±Ø³Ù†Ù„ÛŒ", how="left")

            # Replace NaN values in 'Ù†Ù…Ø±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ' with 0 for sorting
            merged_df["Ù†Ù…Ø±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ"] = merged_df["Ù†Ù…Ø±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ"].fillna(0)

            # Group and sort based on similarity and final scores
            top_personnel = (
                merged_df.groupby("Ú©Ø¯ Ù¾Ø±Ø³Ù†Ù„ÛŒ")
                .agg({"Ø§Ù…ØªÛŒØ§Ø² Ø´Ø¨Ø§Ù‡Øª": "mean", "Ù†Ù…Ø±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ": "mean"})
                .reset_index()
                .sort_values(by=["Ø§Ù…ØªÛŒØ§Ø² Ø´Ø¨Ø§Ù‡Øª", "Ù†Ù…Ø±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ"], ascending=[False, False])  # Sorting
                .head(10)  # Select top 10
            )

            # Display top personnel with similarity score and final scores
            st.subheader("âœ… Ø§ÙØ±Ø§Ø¯ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ù…Øª:")
            st.table(top_personnel)
        else:
            st.warning("Ø´Ø§Ø®ØµÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ù…Øª Ø§Ù†ØªØ®Ø§Ø¨â€ŒØ´Ø¯Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
    else:
        st.error("Ø³Ù…Øª ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù‡ Ø¯Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
